---
apiVersion: v1
kind: ConfigMap
metadata:
  name: hive-config
  labels:
    {{- include "hive-metastore.labels" . | nindent 4 }}
data:
  metastore-exec-log4j2.properties: |
    status = INFO
    name = MetastoreLog4j2
    packages = org.apache.hadoop.hive.metastore

    # list of properties
    property.metastore.log.level = DEBUG
    property.metastore.root.logger = console
    property.metastore.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
    property.metastore.log.file = metastore.log

    # list of all appenders
    appenders = console

    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n

    # list of all loggers
    loggers = DataNucleus, Datastore, JPOX

    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR

    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR

    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR

    # root logger
    rootLogger.level = ${sys:metastore.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:metastore.root.logger}

  metastore-log4j2.properties: |
    status = INFO
    name = MetastoreLog4j2
    packages = org.apache.hadoop.hive.metastore

    # list of properties
    property.metastore.log.level = DEBUG
    property.metastore.root.logger = console
    property.metastore.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
    property.metastore.log.file = metastore.log

    # list of all appenders
    appenders = console

    # console appender
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n

    # list of all loggers
    loggers = DataNucleus, Datastore, JPOX

    logger.DataNucleus.name = DataNucleus
    logger.DataNucleus.level = ERROR

    logger.Datastore.name = Datastore
    logger.Datastore.level = ERROR

    logger.JPOX.name = JPOX
    logger.JPOX.level = ERROR

    # root logger
    rootLogger.level = ${sys:metastore.log.level}
    rootLogger.appenderRefs = root
    rootLogger.appenderRef.root.ref = ${sys:metastore.root.logger}

  jmx-config.yaml: |
    ---
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    attrNameSnakeCase: true
    whitelistObjectNames:
      - 'metrics:name=active_calls_*'
      - 'metrics:name=api_*'
      - 'metrics:name=create_*'
      - 'metrics:name=delete_*'
      - 'metrics:name=init_*'
      - 'metrics:name=exec_*'
      - 'metrics:name=hs2_*'
      - 'metrics:name=open_connections'
      - 'metrics:name=open_operations'
    rules:
      - pattern: 'metrics<name=(.*)><>Value'
        name: hive_$1
        type: GAUGE
      - pattern: 'metrics<name=(.*)><>Count'
        name: hive_$1_count
        type: GAUGE
      - pattern: 'metrics<name=(.*)><>(\d+)thPercentile'
        name: hive_$1
        type: GAUGE
        labels:
          quantile: "0.$2"

  metastore-site.xml: |  
    <configuration>
      <property>
        <name>metastore.enable.doAs</name>
        <value>false</value>
      </property>
      <property>
        <name>metastore.use.SSL</name>
        <value>false</value>
      </property>
      <property>
        <name>metastore.authentication</name>
        <value>NOSASL</value>
      </property>
      <property>
        <name>metastore.thrift.port</name>
        <value>9083</value>
        <description>Hive metastore listener port</description>
      </property>
      <property>
        <name>metastore.thrift.uris</name>
        <value>thrift://hive-metastore:9083</value>
        <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
      </property>
      <property>
        <name>metastore.metrics.enabled</name>
        <value>true</value>
        <description>Enable metrics on the metastore.</description>
      </property>
      <property>
        <name>metastore.metrics.reporters</name>
        <value>jmx</value>
        <description>A comma separated list of metrics reporters to start</description>
      </property>
      <property>
        <name>datanucleus.autoStartMechanismMode</name>
        <value>ignored</value>
        <description>Autostart mechanism for datanucleus.  Currently ignored is the only option supported.</description>
      </property>
      <property>
        <name>datanucleus.schema.autoCreateAll</name>
        <value>false</value>
        <description>Auto creates necessary schema on a startup if one doesn't exist. Set this to false, after creating it once.To enable auto create also set hive.metastore.schema.verification=false. Auto creation is not recommended for production use cases, run schematool command instead.</description>
      </property>
      <property>
        <name>hive.metastore.schema.verification</name>
        <value>true</value>
        <description>
          Enforce metastore schema version consistency.
          True: Verify that version information stored in is compatible with one from Hive jars.  Also disable automatic
                schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures
                proper metastore schema migration. (Default)
          False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.
        </description>
      </property>
      <property>
        <name>hive.default.fileformat</name>
        <value>Parquet</value>
      </property>
      <property>
        <name>fs.s3a.endpoint</name>
        <description>AWS S3 endpoint to connect to.</description>
        <value>XXX_S3ENDPOINT_XXX</value>
      </property>
      <property>
        <name>fs.s3a.access.key</name>
        <description>AWS access key ID.</description>
        <value>XXX_S3_ACCESS_KEY_XXX</value>
      </property>
      <property>
        <name>fs.s3a.secret.key</name>
        <description>AWS secret key.</description>
        <value>XXX_S3_SECRET_XXX</value>
      </property>
      <property>
        <name>fs.s3a.path.style.access</name>
        <value>true</value>
        <description>Enable S3 path style access.</description>
      </property>
      <property>
        <name>fs.s3a.endpoint.region</name>
        <value>us-east-1</value>
      </property>
      <property>
        <name>metastore.warehouse.dir</name>
        <value>s3a://XXX_S3_BUCKET_DIR_XXX/</value>
      </property>
      <property>
        <name>hive.metastore.db.type</name>
        <value>POSTGRES</value>
        <description>
          Expects one of [derby, oracle, mysql, mssql, postgres].
          Type of database used by the metastore. Information schema &amp; JDBCStorageHandler depend on it.
        </description>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>XXX_DATABASE_USER_XXX</value>
        <description>Username to use against metastore database</description>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>XXX_DATABASE_PASSWORD_XXX</value>
        <description>password to use against metastore database</description>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:XXX_DATABASE_CONNECT_URL_XXX</value>
        <description>
          JDBC connect string for a JDBC metastore.
          To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
          For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
        </description>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
      </property>
      <property>
        <name>hive.cluster.delegation.token.store.class</name>
        <value>org.apache.hadoop.hive.thrift.DBTokenStore</value>
      </property>
      <property>
        <name>metastore.task.threads.always</name>
        <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask</value>
      </property>
      <property>
        <name>metastore.expression.proxy</name>
        <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
      </property>
    </configuration>